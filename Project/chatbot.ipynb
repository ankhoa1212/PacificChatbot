{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82154a8d9818f810"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Clean the data file by removing non-text (e.g. emojis, smart quotes) and␣regularizing text\n",
    "#(e.g. tokenization, lower casing, stemming, lemmatizing, POS tagging, stopword removal, removing punctuation, spelling correction)\n",
    "import demoji\n",
    "import json\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "path= \"../Dataset/University_data.json\"\n",
    "with open(path, 'r',encoding=\"UTF-8\") as json_file:\n",
    "    text = json.load(json_file)\n",
    "categories = []\n",
    "all_text = \"\"\n",
    "for key, faq_list in text.items():\n",
    "    group_text = \"\"\n",
    "    for faq_item in faq_list:\n",
    "        all_text += faq_item[\"question\"] + \" \" +faq_item[\"answer\"] + \" \"\n",
    "        group_text += faq_item[\"question\"] + faq_item[\"answer\"]\n",
    "    categories.append(group_text)\n",
    "    \n",
    "# Removing emojis\n",
    "clean_text = demoji.replace(all_text,\"\")\n",
    "#remove smart quotes\n",
    "clean_text = clean_text.replace(\"“\", \"\\\"\").replace(\"”\",\"\\\"\")\n",
    "# convert text to lower-case\n",
    "clean_text = clean_text.lower()\n",
    "spell = SpellChecker()\n",
    "stemmer = PorterStemmer()\n",
    "# Find and correct spelling errors\n",
    "corrected_text = []\n",
    "clean_text=clean_text.split()\n",
    "for word in clean_text:\n",
    "    # Check if the word is misspelled\n",
    "    if spell.unknown([word]):\n",
    "        # Get the corrected version of the word\n",
    "        corrected_word = spell.correction(word)\n",
    "        # Check if the corrected word is not None\n",
    "        if corrected_word is not None:\n",
    "            corrected_text.append(corrected_word)\n",
    "        else:\n",
    "            # If the correction is None, keep the original word\n",
    "            corrected_text.append(word)\n",
    "    else:\n",
    "        corrected_text.append(word)\n",
    "        \n",
    "# Join the corrected words back into a string\n",
    "corrected_text = \" \".join(corrected_text)\n",
    "#Tokenzing using Spacy with removing white spaces, stop words, and punctuations\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(corrected_text)\n",
    "# Lemmatize and stem the words\n",
    "lemmatized_and_stemmed_words = []\n",
    "for token in doc:\n",
    "    lemma = token.lemma_\n",
    "    stem = stemmer.stem(token.text) # Use Porter Stemmer\n",
    "    lemmatized_and_stemmed_words.append((token.text, lemma, stem))\n",
    "clean_words = [token.text for token in doc if not (token.is_space or token.is_stop or token.is_punct)]\n",
    "posArray = [(token.text, token.pos_) for token in doc if not (token.is_space or token.is_stop or token.is_punct)]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-14T08:52:53.394483200Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your JSON data\n",
    "path= \"../Dataset/University_data.json\"\n",
    "with open(path, 'r', encoding=\"UTF-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract questions and labels\n",
    "questions = []\n",
    "labels = []\n",
    "\n",
    "for category, faqs in data.items():\n",
    "    for faq in faqs:\n",
    "        questions.append(faq['question'])\n",
    "        # Append the label for each FAQ\n",
    "        labels.append(category)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(questions, labels, test_size=0.2, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T08:50:37.323323200Z",
     "start_time": "2023-11-14T08:50:37.295289200Z"
    }
   },
   "id": "8d15050266a274a7"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "# Create a CountVectorizer to convert text into a numerical format\n",
    "vectorizer = CountVectorizer()\n",
    "# Fit the vectorizer on the training data and transform the data\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T08:50:40.144375900Z",
     "start_time": "2023-11-14T08:50:40.124501300Z"
    }
   },
   "id": "f9af073ccb63ed01"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# train the naive bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Initialize the classifier and train it\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T08:52:47.510319500Z",
     "start_time": "2023-11-14T08:52:47.495338700Z"
    }
   },
   "id": "90c5c76f62548b53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "def svm_classifier(X_train, y_train, X_test):\n",
    "    return y_pred\n",
    "\n",
    "def bert_classifier(X_train, y_train, X_test):\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def neural_network(X_train, y_train, X_test):\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "# SVM\n",
    "svm_predictions = svm_classifier(X_train, y_train, X_test)\n",
    "\n",
    "# BERT\n",
    "#bert_predictions = bert_classifier(X_train, y_train, X_test)\n",
    "\n",
    "# Neural Network\n",
    "#nn_predictions = neural_network(X_train, y_train, X_test)\n",
    "\n",
    "# Compare the models and evaluate their performance\n",
    "#print(f'SVM Accuracy: {accuracy_score(y_test, svm_predictions)}')\n",
    "#print(f'BERT Accuracy: {accuracy_score(y_test, bert_predictions)}')\n",
    "#print(f'Neural Network Accuracy: {accuracy_score(y_test, nn_predictions)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2851aabb20c8142f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-14T08:28:35.802624200Z"
    }
   },
   "id": "f3b01e4d0eb3244b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
