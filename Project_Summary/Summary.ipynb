{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "268b04d6e4c11c0b",
   "metadata": {},
   "source": [
    "# Classification is based on the University Dataset\n",
    "## Problem Statement 1:\n",
    "\n",
    "As the project involves creating a university chatbot, we aim to build a binary classification model to determine whether the text refers to program-related data or general university data. The dataset includes information on various aspects such as Pacific card, housing, dining, and course-related details. We categorize the data into academic and non-academic labels for classification.\n",
    "\n",
    "## Classification Method Comparison\n",
    "\n",
    "### Naïve Bayes\n",
    "- **Accuracy**: 0.7951\n",
    "- **Classification Report**:\n",
    "   - Precision: 0.93 (Non-academic), 0.73 (Academic)\n",
    "   - Recall: 0.63 (Non-academic), 0.95 (Academic)\n",
    "   - F1-Score: 0.75 (Non-academic), 0.82 (Academic)\n",
    "   - Support: 873 (Non-academic), 899 (Academic)\n",
    "\n",
    "### Support Vector Classifier (SVC)\n",
    "- **Accuracy**: 0.9644\n",
    "- **Classification Report**:\n",
    "   - Precision: 0.94 (Non-academic), 0.99 (Academic)\n",
    "   - Recall: 0.99 (Non-academic), 0.94 (Academic)\n",
    "   - F1-Score: 0.96 (Non-academic), 0.96 (Academic)\n",
    "   - Support: 873 (Non-academic), 899 (Academic)\n",
    "\n",
    "### Multilayer Perceptron (MLP)\n",
    "- **Model Parameters**: 1,001\n",
    "- **Sequential Model Layers**: 5\n",
    "- **Training Accuracy**: 0.9972\n",
    "- **Testing Accuracy**: 0.9554\n",
    "\n",
    "### BERT Model Evaluation Summary\n",
    "- **Training Metrics**:\n",
    "  - Loss: 0.0143\n",
    "  - Accuracy: 99.78%\n",
    "\n",
    "In summary, we applied four different classification methods to solve a binary classification problem. Here are the results:\n",
    "\n",
    "- **Naïve Bayes**: Achieved an accuracy of 0.7951 with precision, recall, and F1-scores for both classes.\n",
    "- **Support Vector Classifier (SVC)**: Achieved an accuracy of 0.9644 with high precision, recall, and F1-scores for both classes, indicating excellent performance.\n",
    "- **Multilayer Perceptron (MLP)**: Achieved a training accuracy of 0.9972 and a testing accuracy of 0.9554, showing strong performance on the testing data.\n",
    "- **BERT Model**: During training, the model achieved a low loss of 0.0143 and a high accuracy of 99.78%.\n",
    "\n",
    "## Analysis:\n",
    "\n",
    "- **SVC** demonstrates the highest accuracy (96.44%) among all models.\n",
    "- SVC achieves high precision, recall, and F1-scores for both non-academic and academic classes, indicating strong overall performance.\n",
    "- **Naïve Bayes** has a lower accuracy (79.51%) compared to SVC and lower precision, recall, and F1-scores for academic-related data.\n",
    "- **MLP** performs well but has a slightly lower testing accuracy (95.54%) compared to SVC.\n",
    "- **BERT** shows excellent training metrics, but specific testing accuracy and other metrics are not provided.\n",
    "\n",
    "## Conclusion:\n",
    "\n",
    "Based on the provided results, the **BERT** is the top-performing model for this binary classification task. It achieves the highest accuracy and robust precision, recall, and F1-scores for both academic and non-academic classes. Therefore, BERT is the recommended model for this university-related text classification problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacdc861656c80ae",
   "metadata": {},
   "source": [
    "## Problem Statement 2:\n",
    "\n",
    "As the project involves creating a university chatbot, we aim to build a binary classification model to determine whether the text refers to housing or not.\n",
    "\n",
    "## Classification Method Comparison\n",
    "\n",
    "### Naïve Bayes\n",
    "- **Accuracy**: 0.9667\n",
    "\n",
    "\n",
    "### Support Vector Classifier (SVC)\n",
    "- **Accuracy**: 0.9333\n",
    "\n",
    "### Multilayer Perceptron (MLP)\n",
    "- **Model Parameters**: 955\n",
    "- **Sequential Model Layers**: 6\n",
    "- **Training Accuracy**: 1.0000\n",
    "- **Testing Accuracy**: 0.9783\n",
    "\n",
    "### BERT Model Evaluation Summary\n",
    "- **Training Accuracy:** 1.0000\n",
    "- **Testing Accuracy:** 0.9928\n",
    "\n",
    "In summary, we applied four different classification methods to solve a binary classification problem. Here are the results:\n",
    "\n",
    "- **Naïve Bayes**: Achieved an accuracy of 0.9667.\n",
    "- **Support Vector Classifier (SVC)**: Achieved an accuracy of 0.9333.\n",
    "- **Multilayer Perceptron (MLP)**: Achieved a training accuracy of 1.0000 and a testing accuracy of 0.9783, showing strong performance on the testing data.\n",
    "- **BERT Model**: Achieved a training accuracy of 1.0000 and a testing accuracy of 0.9928, it also shows strong performance on the testing data.\n",
    "\n",
    "## Conclusion:\n",
    "\n",
    "    For the university chatbot, the dataset is in JSON format containing categories. Based on the classification results, **BERT** is the recommended model because it achieved near perfect test accuracy of 0.9928. This excellent accuracy means BERT can very accurately determine if text relates to housing or not. The MLP model also performed well, but BERT had slightly higher test accuracy. Overall, for this JSON dataset with categories, BERT is the optimal choice to maximize classification accuracy for the university chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d0f7187745058b",
   "metadata": {},
   "source": [
    "## Problem Statement 3:\n",
    "\n",
    "As the project involves creating a university chatbot, we aim to build a binary classification model to determine whether the text is related to something academic or not. The dataset contains information collected from webpages related to the university.\n",
    "\n",
    "## Classification Method Comparison\n",
    "\n",
    "### Naïve Bayes\n",
    "- **Accuracy**: 0.5705\n",
    "\n",
    "\n",
    "### Support Vector Classifier (SVC)\n",
    "- **Accuracy**: 0.9195\n",
    "\n",
    "### Multilayer Perceptron (MLP)\n",
    "- **Model Parameters**: 465\n",
    "- **Sequential Model Layers**: 2\n",
    "- **Training Accuracy**: 0.9428\n",
    "- **Testing Accuracy**: 0.9262\n",
    "\n",
    "### BERT Model Evaluation Summary\n",
    "- **Training Metrics**:\n",
    "  - Loss: 0.2598\n",
    "  - Accuracy: 88.58%\n",
    "\n",
    "In summary, we applied four different classification methods to solve a binary classification problem. Here are the results:\n",
    "\n",
    "- **Naïve Bayes**: Achieved an accuracy of 0.5705.\n",
    "- **Support Vector Classifier (SVC)**: Achieved an accuracy of 0.9195.\n",
    "- **Multilayer Perceptron (MLP)**: Achieved a training accuracy of 0.9428 and a testing accuracy of 0.9262, showing strong performance on the testing data.\n",
    "- **BERT Model**: During training, the model achieved a low loss of 0.2598 and a high accuracy of 88.58%.\n",
    "\n",
    "## Conclusion:\n",
    "\n",
    "Based on the provided results, the **Multilayer Perceptron (MLP)** is the top-performing model for this binary classification task. It achieves the highest accuracy for identifying academic and non-academic classes. Therefore, MLP is the recommended model for the academic and non-academic text classification problem.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
